{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"clustering_validation","provenance":[{"file_id":"1gyGeh0F4yDfsrbw84CptHzlgh_1EtXmq","timestamp":1594152171823},{"file_id":"1LdAVy1Kcg2EhYkARHKsZgt-z8ffLa01Q","timestamp":1593625373486},{"file_id":"1c3Kb1-VoVGWcren7QQBvShjn1pbv4Ltf","timestamp":1593622979501}],"mount_file_id":"1gkLlbNC1sZ2783yF78LC7UxMjk3Vebea","authorship_tag":"ABX9TyO1IB9PwWul+UqtRsIjJ51n"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"CVNZSE4NBYAV","colab_type":"text"},"source":["# Clustering Validation"]},{"cell_type":"markdown","metadata":{"id":"43SZmB8U1JBb","colab_type":"text"},"source":["# External Measures"]},{"cell_type":"markdown","metadata":{"id":"gFS-5VEkq8u1","colab_type":"text"},"source":["Let $\\mathbf{D}$ be a dataset consiting of $n$ points $\\mathbf{x}_{i}$ in  a $d$_demensional space, partitioned into $k$ clusters. Let $y_{i}\\in \\{1, 2, ..., k\\}$ denote the ground-truth cluster membership or label information for each point. The ground-truth clustering is given as $\\mathcal{T}=\\{T_{1}, T_{2}, ..., T_{k}\\}$, where the cluster $T_{j}$ consists of all the points with label $j$, i.e., $T_{j}=\\{\\mathbf{x}_{i}\\in \\mathbf{D}|y_{i}=j\\}$. Also let $\\mathcal{C}=\\{C_{1}, C_{2}, ..., C{r}\\}$ denote a clustering of the same dataset into $r$ clusters, obtained via some clustering algorithm, and let $\\hat{y_{i}}\\in \\{1, 2, ..., r\\}$ denote the cluster label for $\\mathbf{x}_{i}$. For clarity, henceforth, we will refer to $\\mathcal{T}$ as the ground-truth partitioning, and to teach $T_{i}$ as a partition. We will call $\\mathcal{C}$ a clustering, with each $C_{i}$ referred to as a cluster. Because the ground truth is assumed to be known, typically clustering methods will be run with the correct number of clusters, that is, with $r=k$. However, to keep the discussion more general, we allow $r$ to be different from $k$."]},{"cell_type":"markdown","metadata":{"id":"BKgiHONWuWJJ","colab_type":"text"},"source":["External evaluation measures try capture the extent to which points from the same partition appear in the  same cluster, and the extent to which points from different partitions are grouped in different clusters. There is usually a trade-off between these two goals, which is either explicitly captured by a measure or is implicit in its computation. All of the external measures rely on the $r\\times k$ contingency table $\\mathbf{N}$ that is induced by a clustering $\\mathcal{C}$ and the ground-truth partitioning $\\mathcal{T}$, defined as follows:\n","$$\\mathbf{N}(i, j)=n_{ij}=|C_{i}\\cap T_{j}|$$\n","In other words, the count $n_{ij}$ denotes the number of points that are common to cluster $C_{i}$ and ground-truth partition $T_{j}$. Further, for clarity, let $n_{i}=|C_{i}|$ denote the number of points in cluster $C_{i}$, and $m_{j}=|T_{j}|$ denote the number of points in partition $T_{j}$. The contingency table can be computed from $\\mathcal{T}$ and $\\mathcal{C}$ in $O(n)$ time by examining the partition and cluster labels, $y_{i}$ and $\\hat{y_{i}}$, for each point $\\mathbf{x}_{i}\\in \\mathbf{D}$ and incrementing the corresponding count $n_{y_{i}\\hat{y_{i}}}$ or $n_{\\hat{y_{i}}y_{i}}$."]},{"cell_type":"markdown","metadata":{"id":"Mks7kkWxxjQq","colab_type":"text"},"source":["Scikit Learn Clustering Evaluation Section: https://scikit-learn.org/stable/modules/clustering.html#clustering-evaluation"]},{"cell_type":"code","metadata":{"id":"YrTJONKUDzDE","colab_type":"code","colab":{}},"source":["from sklearn.cluster import KMeans\n","from sklearn.metrics.cluster import contingency_matrix\n","from sklearn.metrics import adjusted_rand_score\n","from sklearn.metrics import adjusted_mutual_info_score\n","from sklearn.metrics import homogeneity_completeness_v_measure\n","from sklearn.metrics import fowlkes_mallows_score"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Lyy16rWSIC0T","colab_type":"code","colab":{}},"source":["# Compute the purity between the clusters and given partitions\n","from sklearn.metrics.cluster import contingency_matrix\n","def purity(labels_true, labels_pred):\n","    '''\n","        input: labels_true: an array of labels of the given partitions\n","               labels_pred: an array of labels of the clusters\n","        return: the purity between the partitions and clusters\n","    '''\n","    # contingency matrix\n","    cmat = contingency_matrix(labels_true, labels_pred)\n","\n","    return (cmat.max(axis=0) / cmat.sum()).sum()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"cmS_XMO_KvW1","colab_type":"code","colab":{}},"source":["# Compute the F-measure between the clusters and given partitions\n","from sklearn.metrics.cluster import contingency_matrix\n","def fmeasure(labels_true, labels_pred):\n","    '''\n","        input: labels_true: an array of labels of the given partitions\n","               labels_pred: an array of labels of the clusters\n","        return: the F-measure between the partitions and clusters\n","    '''\n","    # contingency matrix\n","    cmat = contingency_matrix(labels_true, labels_pred)\n","\n","    # precision for each cluster\n","    precisions = cmat.max(axis=0) / cmat.sum(axis=0)\n","\n","    # max count for each cluster\n","    maxes = cmat.max(axis=0)\n","    # partition index for each cluster with max count\n","    part_idxs = cmat.argmax(axis=0)\n","    # partition sum for each correspoding cluster with max count\n","    part_sums = cmat[part_idxs].sum(axis=1)\n","\n","    # recall for each cluster\n","    recalls = maxes / part_sums\n","\n","    return (2/(1/recalls + 1/precisions)).mean()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"9kniIp6nXpXd","colab_type":"code","colab":{}},"source":["# Compute a series of clustering validation measures\n","from sklearn.metrics.cluster import contingency_matrix\n","from sklearn.metrics import adjusted_rand_score\n","from sklearn.metrics import adjusted_mutual_info_score\n","from sklearn.metrics import homogeneity_completeness_v_measure\n","from sklearn.metrics import fowlkes_mallows_score\n","def clustering_measures(labels_true, labels_pred):\n","    '''\n","        input: labels_true: an array of labels of the given partitions\n","               labels_pred: an array of labels of the clusters\n","        return: a dictionary contains validation measures\n","    '''    \n","\n","    ans = {}\n","    ans['purity'] = purity(labels_true, labels_pred)\n","    ans['fMeasure'] = fmeasure(labels_true, labels_pred)\n","\n","    ans['rand'] = adjusted_rand_score(labels_true, labels_pred)\n","\n","    ans['mutInfo'] = adjusted_mutual_info_score(labels_true, labels_pred)\n","\n","    homo, comp, vm = homogeneity_completeness_v_measure(labels_true, labels_pred)\n","    ans['homogeneity'] = homo\n","    ans['completeness'] = comp\n","    ans['vMeasure'] = vm\n","\n","    ans['fowMal'] = fowlkes_mallows_score(labels_true, labels_pred)\n","\n","    return ans"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"4vahE31Mbk5u","colab_type":"code","colab":{}},"source":[""],"execution_count":null,"outputs":[]}]}